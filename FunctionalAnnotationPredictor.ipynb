{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQJXFi0q5hJM"
      },
      "source": [
        "# Final implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxpjDhYXf7Rp",
        "outputId": "e138e300-f702-4379-bf02-14d22d23de61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# @title Connect to drive and helper function\n",
        "from google.colab import drive\n",
        "# Mount the drive shared with you.\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "def open_file(base_path, file_name):\n",
        "  file_path = base_path + file_name\n",
        "  try:\n",
        "      with open(file_path, 'rb') as f:\n",
        "          loaded_object = pd.read_pickle(f)\n",
        "      print(f\"Successfully loaded object from {file_path}\")\n",
        "      return loaded_object\n",
        "  except FileNotFoundError:\n",
        "      print(f\"Error: The file {file_path} was not found. Please check the path.\")\n",
        "  except Exception as e:\n",
        "      print(f\"An error occurred: {e}\")\n",
        "\n",
        "base_path = '/content/gdrive/MyDrive/Postgrado/Machine learning/Final_Proyect/'\n",
        "pkl_folder_path = 'data/alphafoldDB_pdb_1115/'\n",
        "json_file_path = 'data/deepseq-af2-structures-merged_data-12632.json'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqJSea4U6vu9"
      },
      "source": [
        "## Deep seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zywb1Qh78pw3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "#@title Load and split json\n",
        "import json\n",
        "import random\n",
        "\n",
        "def load_and_split_json(json_path, train_frac=0.8, val_frac=0.1, seed=42):\n",
        "    with open(json_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    all_ids = list(data.keys())\n",
        "    random.seed(seed)\n",
        "    random.shuffle(all_ids)\n",
        "\n",
        "    N = len(all_ids)\n",
        "    train_ids = all_ids[:int(train_frac * N)]\n",
        "    val_ids = all_ids[int(train_frac * N):int((train_frac + val_frac) * N)]\n",
        "    test_ids = all_ids[int((train_frac + val_frac) * N):]\n",
        "\n",
        "    return data, train_ids, val_ids, test_ids\n",
        "\n",
        "# Standard amino acids + padding\n",
        "AMINO_ACID_VOCAB = {\n",
        "    'A': 1, 'R': 2, 'N': 3, 'D': 4, 'C': 5, 'E': 6, 'Q': 7, 'G': 8, 'H': 9, 'I': 10,\n",
        "    'L': 11, 'K': 12, 'M': 13, 'F': 14, 'P': 15, 'S': 16, 'T': 17, 'W': 18, 'Y': 19, 'V': 20,\n",
        "    'X': 21,  # Unknown\n",
        "    'B': 22,  # Aspartic acid or Asparagine\n",
        "    'Z': 23   # Glutamic acid or Glutamine\n",
        "}\n",
        "PAD_TOKEN_ID = 0\n",
        "\n",
        "def encode_sequence(seq, max_len=2000):\n",
        "    \"\"\"\n",
        "    Encode an amino acid sequence to a list of integers with padding.\n",
        "    Unknown amino acids are mapped to 'X'.\n",
        "    Ensure the output is always a list of integers.\n",
        "    \"\"\"\n",
        "    encoded = [AMINO_ACID_VOCAB.get(aa, AMINO_ACID_VOCAB['X']) for aa in seq]\n",
        "    if len(encoded) < max_len:\n",
        "        encoded += [PAD_TOKEN_ID] * (max_len - len(encoded))\n",
        "    else:\n",
        "        encoded = encoded[:max_len]\n",
        "    return encoded # Return as list of integers\n",
        "\n",
        "def encode_go_terms(go_terms, go_term_to_index):\n",
        "    \"\"\"\n",
        "    Encode a list of GO terms as a multi-hot binary vector.\n",
        "\n",
        "    Args:\n",
        "        go_terms: List of GO term strings, e.g., ['GO:0001234', 'GO:0005678']\n",
        "        go_term_to_index: Dict mapping GO term → integer index\n",
        "\n",
        "    Returns:\n",
        "        numpy array (shape: num_go_terms,) with 1.0 for present terms\n",
        "    \"\"\"\n",
        "    num_go_terms = len(go_term_to_index)\n",
        "    label_vector = np.zeros(num_go_terms, dtype=np.float32)\n",
        "\n",
        "    for term in go_terms:\n",
        "        idx = go_term_to_index.get(term)\n",
        "        if idx is not None:\n",
        "            label_vector[idx] = 1.0\n",
        "\n",
        "    return label_vector\n",
        "\n",
        "def extract_go_terms_from_json(data):\n",
        "\n",
        "    all_go_terms = set()\n",
        "\n",
        "    for protein_id, entry in data.items():\n",
        "        go_terms = entry.get(\"true_go\", [])\n",
        "        all_go_terms.update(go_terms)\n",
        "\n",
        "    # Sort for consistent ordering\n",
        "    go_term_vocabulary = sorted(list(all_go_terms))\n",
        "    go_term_to_index = {term: i for i, term in enumerate(go_term_vocabulary)}\n",
        "    num_go_terms = len(go_term_vocabulary)\n",
        "\n",
        "    return go_term_vocabulary, go_term_to_index, num_go_terms\n",
        "\n",
        "\n",
        "def get_sequence_and_labels(data, ids, max_len=2000, go_term_to_index=None):\n",
        "    X, Y = [], []\n",
        "    for pid in ids:\n",
        "        seq = data[pid].get('seq_from_pkl', '')\n",
        "        go_terms = data[pid].get('true_go', [])\n",
        "        # encode seq to integers, pad, etc.\n",
        "        seq_encoded = encode_sequence(seq, max_len)\n",
        "        go_encoded = encode_go_terms(go_terms, go_term_to_index)\n",
        "        X.append(seq_encoded)\n",
        "        Y.append(go_encoded)\n",
        "    # Convert to numpy arrays with appropriate dtype\n",
        "    return np.array(X, dtype=np.int32), np.array(Y, dtype=np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XpeKAZFUAusL"
      },
      "outputs": [],
      "source": [
        "json_data, train_ids, val_ids, test_ids = load_and_split_json(base_path + json_file_path)\n",
        "go_term_vocabulary, go_term_to_index, num_go_terms = extract_go_terms_from_json(json_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdQWcelKyol0"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwedRrI2SPb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4979faff-d4e7-4387-b527-4449560c9b96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 147ms/step - accuracy: 0.0847 - loss: 0.6744 - val_accuracy: 0.2193 - val_loss: 0.6200\n",
            "Epoch 2/20\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 78ms/step - accuracy: 0.1051 - loss: 0.6032 - val_accuracy: 0.1607 - val_loss: 0.5548\n",
            "Epoch 3/20\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 78ms/step - accuracy: 0.0487 - loss: 0.5400 - val_accuracy: 0.0000e+00 - val_loss: 0.4973\n",
            "Epoch 4/20\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 79ms/step - accuracy: 0.0476 - loss: 0.4843 - val_accuracy: 0.0000e+00 - val_loss: 0.4474\n",
            "Epoch 5/20\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 80ms/step - accuracy: 0.0546 - loss: 0.4353 - val_accuracy: 0.0000e+00 - val_loss: 0.4041\n",
            "Epoch 6/20\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 81ms/step - accuracy: 0.0662 - loss: 0.3921 - val_accuracy: 0.0103 - val_loss: 0.3634\n",
            "Epoch 7/20\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 83ms/step - accuracy: 0.0627 - loss: 0.3541 - val_accuracy: 0.0333 - val_loss: 0.3294\n",
            "Epoch 8/20\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 80ms/step - accuracy: 0.0748 - loss: 0.3207 - val_accuracy: 0.0293 - val_loss: 0.2996\n",
            "Epoch 9/20\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 80ms/step - accuracy: 0.0704 - loss: 0.2909 - val_accuracy: 0.0048 - val_loss: 0.2712\n",
            "Epoch 10/20\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 79ms/step - accuracy: 0.0989 - loss: 0.2648 - val_accuracy: 0.0800 - val_loss: 0.2468\n",
            "Epoch 11/20\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 80ms/step - accuracy: 0.1020 - loss: 0.2416 - val_accuracy: 0.1283 - val_loss: 0.2266\n",
            "Epoch 12/20\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 80ms/step - accuracy: 0.1060 - loss: 0.2209 - val_accuracy: 0.1346 - val_loss: 0.2076\n",
            "Epoch 13/20\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 81ms/step - accuracy: 0.1145 - loss: 0.2026 - val_accuracy: 0.0926 - val_loss: 0.1901\n",
            "Epoch 14/20\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 84ms/step - accuracy: 0.1257 - loss: 0.1860 - val_accuracy: 0.0998 - val_loss: 0.1762\n",
            "Epoch 15/20\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 80ms/step - accuracy: 0.1329 - loss: 0.1710 - val_accuracy: 0.1441 - val_loss: 0.1622\n",
            "Epoch 16/20\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 80ms/step - accuracy: 0.1383 - loss: 0.1579 - val_accuracy: 0.1006 - val_loss: 0.1503\n",
            "Epoch 17/20\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 81ms/step - accuracy: 0.1503 - loss: 0.1459 - val_accuracy: 0.1346 - val_loss: 0.1394\n",
            "Epoch 18/20\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 81ms/step - accuracy: 0.1426 - loss: 0.1351 - val_accuracy: 0.1576 - val_loss: 0.1298\n",
            "Epoch 19/20\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 80ms/step - accuracy: 0.1513 - loss: 0.1252 - val_accuracy: 0.1694 - val_loss: 0.1195\n",
            "Epoch 20/20\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 83ms/step - accuracy: 0.1570 - loss: 0.1165 - val_accuracy: 0.1552 - val_loss: 0.1113\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n"
          ]
        }
      ],
      "source": [
        "#@title Deepseq implementation\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Conv1D, Dropout, GlobalAveragePooling1D, Dense, BatchNormalization, Activation\n",
        "\n",
        "# Deep seq model\n",
        "def build_model(max_sequence_size, num_amino_acids, embedding_dims, num_go_terms): # Changed max_num_functions to num_go_terms\n",
        "    input_layer = Input(shape=(max_sequence_size,))\n",
        "\n",
        "    embedding = Embedding(num_amino_acids, embedding_dims, input_length=max_sequence_size)(input_layer)\n",
        "\n",
        "    x = Conv1D(250, 15, activation='relu', strides=1)(embedding)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = Conv1D(100, 15, activation='relu', strides=1)(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "\n",
        "    pooled_output = GlobalAveragePooling1D(name='latent_space')(x)\n",
        "\n",
        "    x = Dense(num_go_terms)(pooled_output) # Changed max_num_functions to num_go_terms\n",
        "    x = BatchNormalization()(x)\n",
        "    output = Activation('sigmoid')(x)\n",
        "\n",
        "    model = Model(inputs=input_layer, outputs=output)\n",
        "    latent_model = Model(inputs=input_layer, outputs=pooled_output)  # Para extraer el espacio latente\n",
        "\n",
        "    return model, latent_model\n",
        "\n",
        "X_train, y_train = get_sequence_and_labels(json_data, train_ids, go_term_to_index=go_term_to_index)\n",
        "X_val, y_val = get_sequence_and_labels(json_data, val_ids, go_term_to_index=go_term_to_index)\n",
        "\n",
        "# Hyperparameters\n",
        "max_sequence_size = 2000\n",
        "num_amino_acids = 24     # 23 aminoácidos + padding (0)\n",
        "embedding_dims = 23\n",
        "# The number of output units should match the number of GO terms\n",
        "# max_num_functions = 5        # O las etiquetas multilabel reales\n",
        "# Use the calculated number of unique GO terms\n",
        "num_go_terms = len(go_term_to_index)\n",
        "\n",
        "\n",
        "model, latent_model = build_model(max_sequence_size, num_amino_acids, embedding_dims, num_go_terms) # Passed num_go_terms\n",
        "\n",
        "# Compile\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',  # multilabel\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Initial training\n",
        "history = model.fit(X_train, y_train,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    epochs=20,\n",
        "                    batch_size=64)\n",
        "\n",
        "# Get latent space representation\n",
        "X_latent_train = latent_model.predict(X_train, batch_size=64)\n",
        "X_latent_val   = latent_model.predict(X_val, batch_size=64)\n",
        "#X_latent_test  = latent_model.predict(X_test, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IrOphtOWLbId"
      },
      "outputs": [],
      "source": [
        "# create dictionary pair protein latent: representation\n",
        "x_train_dict = {}\n",
        "for i, protein_id in enumerate(train_ids):\n",
        "    x_train_dict[protein_id] = X_latent_train[i]\n",
        "\n",
        "x_val_dict = {}\n",
        "for i, protein_id in enumerate(val_ids):\n",
        "    x_val_dict[protein_id] = X_latent_val[i]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AG2iiWSWnhjQ"
      },
      "source": [
        "## Structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ysG8J5w0WaSs"
      },
      "outputs": [],
      "source": [
        "#@title Modified Data Loader for Latent Space Representations\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model, Input\n",
        "import numpy as np\n",
        "import json\n",
        "import pandas as pd\n",
        "import ast\n",
        "\n",
        "class JsonDataLoaderWithLatentSpace(tf.keras.utils.Sequence):\n",
        "    \"\"\"\n",
        "    Modified Keras Sequence for loading protein data with pre-computed latent representations\n",
        "    from DeepSeq model instead of ESM embeddings.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_data, batch_size, go_term_vocabulary,\n",
        "                 go_term_to_index, latent_representations_dict, latent_dim=100,\n",
        "                 coords_mask_plddt_th=70.0, pad_token_id=0, fixed_max_len=1024):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            latent_representations_dict: Dictionary mapping protein_id -> latent_vector\n",
        "                                       where latent_vector is the output from your DeepSeq latent_model\n",
        "            latent_dim: Dimension of the latent space (100 in your DeepSeq model with GlobalAveragePooling1D)\n",
        "            fixed_max_len: The fixed maximum sequence length to use for padding.\n",
        "        \"\"\"\n",
        "        self.in_data = in_data\n",
        "        self.batch_size = batch_size\n",
        "        self.coords_mask_plddt_th = coords_mask_plddt_th\n",
        "        self.pad_token_id = pad_token_id\n",
        "        self.latent_dim = latent_dim\n",
        "        self.fixed_max_len = fixed_max_len # Use a fixed maximum length\n",
        "\n",
        "        # GO term encoding\n",
        "        self.go_term_vocabulary = go_term_vocabulary\n",
        "        self.go_term_to_index = go_term_to_index\n",
        "        self.num_go_terms = len(go_term_vocabulary)\n",
        "\n",
        "        # Latent representations from DeepSeq model\n",
        "        self.latent_representations = latent_representations_dict\n",
        "\n",
        "\n",
        "        # Filter protein IDs to only include those with latent representations\n",
        "        all_protein_ids = set(in_data.keys())\n",
        "        latent_protein_ids = set(self.latent_representations.keys())\n",
        "        self.protein_ids = list(all_protein_ids.intersection(latent_protein_ids))\n",
        "\n",
        "        print(f\"Total proteins in JSON: {len(all_protein_ids)}\")\n",
        "        print(f\"Proteins with latent representations: {len(latent_protein_ids)}\")\n",
        "        print(f\"Final dataset size: {len(self.protein_ids)}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(tf.math.ceil(len(self.protein_ids) / self.batch_size))\n",
        "\n",
        "    def encode_go_terms(self, go_terms_list):\n",
        "        \"\"\"Convert list of GO terms to multi-hot encoded vector\"\"\"\n",
        "        label_vector = np.zeros(self.num_go_terms, dtype=np.float32)\n",
        "        if go_terms_list:  # Check if list is not empty\n",
        "            for go_term in go_terms_list:\n",
        "                if go_term in self.go_term_to_index:\n",
        "                    label_vector[self.go_term_to_index[go_term]] = 1.0\n",
        "        return label_vector\n",
        "\n",
        "    def create_latent_sequence_representation(self, protein_ids):\n",
        "        \"\"\"\n",
        "        Create sequence-like representation from latent vectors.\n",
        "        Since your structural model expects sequence input, we need to broadcast\n",
        "        the latent vector across sequence positions.\n",
        "        \"\"\"\n",
        "        batch_latent_seqs = []\n",
        "\n",
        "        for protein_id in protein_ids:\n",
        "            if protein_id in self.latent_representations:\n",
        "                # Get the latent vector (shape: latent_dim,)\n",
        "                latent_vector = self.latent_representations[protein_id]\n",
        "\n",
        "                # Ensure it's a numpy array with correct shape\n",
        "                if isinstance(latent_vector, tf.Tensor):\n",
        "                    latent_vector = latent_vector.numpy()\n",
        "                latent_vector = np.array(latent_vector, dtype=np.float32)\n",
        "\n",
        "                # If latent_vector is 1D, reshape to (latent_dim,)\n",
        "                if latent_vector.ndim > 1:\n",
        "                    latent_vector = latent_vector.flatten()\n",
        "\n",
        "                # Broadcast latent vector across sequence length\n",
        "                # Shape: (max_len, latent_dim)\n",
        "                latent_seq = np.tile(latent_vector[np.newaxis, :], (self.fixed_max_len, 1)) # Use fixed_max_len\n",
        "\n",
        "            else:\n",
        "                # Fallback: create zero vector if latent representation not found\n",
        "                print(f\"Warning: No latent representation found for {protein_id}\")\n",
        "                latent_seq = np.zeros((self.fixed_max_len, self.latent_dim), dtype=np.float32) # Use fixed_max_len\n",
        "\n",
        "            batch_latent_seqs.append(latent_seq)\n",
        "\n",
        "        return np.array(batch_latent_seqs, dtype=np.float32)\n",
        "\n",
        "    def pad_coords(self, coords_list):\n",
        "        \"\"\"Pad coordinates with zero values and handle invalid coords\"\"\"\n",
        "        padded_coords = []\n",
        "        for coords in coords_list:\n",
        "            if not coords:  # Handle empty coords\n",
        "                coords_array = np.zeros((self.fixed_max_len, 3, 3), dtype=np.float32) # Use fixed_max_len\n",
        "            else:\n",
        "                coords_array = np.array(coords, dtype=np.float32)\n",
        "                # Replace any inf or nan values with 0\n",
        "                coords_array = np.nan_to_num(coords_array, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "\n",
        "                if len(coords_array) < self.fixed_max_len:\n",
        "                    pad_shape = list(coords_array.shape)\n",
        "                    pad_shape[0] = self.fixed_max_len - coords_array.shape[0]\n",
        "                    padding = np.zeros(pad_shape, dtype=np.float32)\n",
        "                    coords_array = np.concatenate([coords_array, padding], axis=0)\n",
        "                else:\n",
        "                    coords_array = coords_array[:self.fixed_max_len]\n",
        "\n",
        "            padded_coords.append(coords_array)\n",
        "        return np.array(padded_coords)\n",
        "\n",
        "    def pad_plddts(self, plddts_list):\n",
        "        \"\"\"Pad pLDDT scores with 0 for padding, normalize to 0-1 range\"\"\"\n",
        "        padded_plddts = []\n",
        "        for plddt in plddts_list:\n",
        "            if not plddt:  # Handle empty plddt\n",
        "                plddt_array = np.zeros(self.fixed_max_len, dtype=np.float32) # Use fixed_max_len\n",
        "            else:\n",
        "                plddt_array = np.array(plddt, dtype=np.float32)\n",
        "                # Clamp pLDDT values to valid range [0, 100] before normalization\n",
        "                plddt_array = np.clip(plddt_array, 0.0, 100.0)\n",
        "                plddt_array = plddt_array / 100.0  # Normalize to 0-1 range\n",
        "\n",
        "                if len(plddt_array) < self.fixed_max_len:\n",
        "                    padding = np.zeros(self.fixed_max_len - len(plddt_array), dtype=np.float32) # Use fixed_max_len\n",
        "                    plddt_array = np.concatenate([plddt_array, padding])\n",
        "                else:\n",
        "                    plddt_array = plddt_array[:self.fixed_max_len]\n",
        "\n",
        "            padded_plddts.append(plddt_array)\n",
        "        return np.array(padded_plddts)\n",
        "\n",
        "    def create_padding_mask(self, sequences):\n",
        "        \"\"\"Create padding mask (1 for real tokens, 0 for padding)\"\"\"\n",
        "        masks = []\n",
        "        for seq in sequences:\n",
        "            seq_len = len(seq) if seq else 0\n",
        "\n",
        "            # Ensure we have at least one valid token to prevent all-zero masks\n",
        "            if seq_len == 0:\n",
        "                seq_len = 1  # Set minimum length to 1\n",
        "\n",
        "            mask = np.ones(seq_len, dtype=np.float32)\n",
        "            if seq_len < self.fixed_max_len: # Use fixed_max_len\n",
        "                padding_mask = np.zeros(self.fixed_max_len - seq_len, dtype=np.float32) # Use fixed_max_len\n",
        "                full_mask = np.concatenate([mask, padding_mask])\n",
        "            else:\n",
        "                full_mask = mask[:self.fixed_max_len] # Use fixed_max_len\n",
        "\n",
        "            # Final safety check: ensure at least one valid position\n",
        "            if np.sum(full_mask) == 0:\n",
        "                full_mask[0] = 1.0  # Set first position as valid\n",
        "\n",
        "            masks.append(full_mask)\n",
        "        return np.array(masks)\n",
        "\n",
        "    def mask_coords_by_plddt(self, coords, plddts):\n",
        "        \"\"\"Mask coordinates where pLDDT < threshold\"\"\"\n",
        "        threshold = self.coords_mask_plddt_th / 100.0\n",
        "        bad_coords_mask = plddts < threshold\n",
        "\n",
        "        # Use 0.0 for masked pLDDT to maintain valid range\n",
        "        masked_plddts = np.where(bad_coords_mask, 0.0, plddts)\n",
        "\n",
        "        if coords.ndim == 4:  # (batch, seq_len, 3, 3)\n",
        "            expanded_mask = bad_coords_mask[..., np.newaxis, np.newaxis]\n",
        "        elif coords.ndim == 3:  # (batch, seq_len, 3)\n",
        "            expanded_mask = bad_coords_mask[..., np.newaxis]\n",
        "        else:\n",
        "            expanded_mask = bad_coords_mask\n",
        "\n",
        "        # Use 0.0 for masked coordinates\n",
        "        masked_coords = np.where(expanded_mask, 0.0, coords)\n",
        "\n",
        "        # Final safety check to remove any remaining inf/nan\n",
        "        masked_coords = np.nan_to_num(masked_coords, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "        masked_plddts = np.nan_to_num(masked_plddts, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "\n",
        "        return masked_coords, masked_plddts\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get batch protein IDs\n",
        "        start_idx = idx * self.batch_size\n",
        "        end_idx = min((idx + 1) * self.batch_size, len(self.protein_ids))\n",
        "        batch_ids = self.protein_ids[start_idx:end_idx]\n",
        "\n",
        "        # Collect batch data\n",
        "        batch_data = []\n",
        "        for protein_id in batch_ids:\n",
        "            loaded_object = self.in_data.get(protein_id, {})\n",
        "            if loaded_object:\n",
        "                extracted_data = {\n",
        "                    'protein': protein_id,\n",
        "                    'seq': loaded_object.get('seq_from_pkl', ''),\n",
        "                    'true_go': loaded_object.get('true_go', []),\n",
        "                    'coords': loaded_object.get('coords', []),\n",
        "                    'plddt': loaded_object.get('plddt', [])\n",
        "                }\n",
        "                batch_data.append(extracted_data)\n",
        "\n",
        "        if not batch_data:\n",
        "            return self._empty_batch()\n",
        "\n",
        "        # Extract data\n",
        "        sequences = [item['seq'] for item in batch_data]\n",
        "        coords_list = [item['coords'] for item in batch_data]\n",
        "        plddts_list = [item['plddt'] for item in batch_data]\n",
        "        true_gos_list = [item['true_go'] for item in batch_data]\n",
        "\n",
        "        # Apply padding for structural data using fixed_max_len\n",
        "        padded_coords = self.pad_coords(coords_list)\n",
        "        padded_plddts = self.pad_plddts(plddts_list)\n",
        "        padding_mask = self.create_padding_mask(sequences)\n",
        "\n",
        "        # Apply coordinate masking based on pLDDT\n",
        "        masked_coords, masked_plddts = self.mask_coords_by_plddt(padded_coords, padded_plddts)\n",
        "\n",
        "        # Create latent sequence representations instead of ESM embeddings\n",
        "        latent_sequences = self.create_latent_sequence_representation(batch_ids)\n",
        "\n",
        "        # Encode GO terms to multi-hot labels\n",
        "        go_labels = []\n",
        "        for go_terms in true_gos_list:\n",
        "            encoded_labels = self.encode_go_terms(go_terms)\n",
        "            go_labels.append(encoded_labels)\n",
        "        go_labels = np.array(go_labels)\n",
        "\n",
        "        # Ensure at least one positive label per sample to avoid all-zero targets\n",
        "        for i, label in enumerate(go_labels):\n",
        "            if np.sum(label) == 0:  # If no GO terms are found\n",
        "                # Set a small probability for the first GO term to avoid all-zero labels\n",
        "                go_labels[i, 0] = 0.01\n",
        "\n",
        "        # Return model inputs and labels\n",
        "        return (\n",
        "            {\n",
        "                'dpseq': tf.constant(latent_sequences, dtype=tf.float32),  # Now contains latent representations\n",
        "                'coords': tf.constant(masked_coords, dtype=tf.float32),\n",
        "                'padding_mask': tf.constant(padding_mask, dtype=tf.float32)\n",
        "            },\n",
        "            tf.constant(go_labels, dtype=tf.float32)\n",
        "        )\n",
        "\n",
        "    def _empty_batch(self):\n",
        "        \"\"\"Return empty batch when no data is available\"\"\"\n",
        "        batch_size = 1\n",
        "        # Use fixed_max_len for empty batch shape\n",
        "        seq_len = self.fixed_max_len\n",
        "        return (\n",
        "            {\n",
        "                'dpseq': tf.constant(np.zeros((batch_size, seq_len, self.latent_dim)), dtype=tf.float32),\n",
        "                'coords': tf.constant(np.zeros((batch_size, seq_len, 3, 3)), dtype=tf.float32),\n",
        "                'padding_mask': tf.constant(np.zeros((batch_size, seq_len)), dtype=tf.float32)\n",
        "            },\n",
        "            tf.constant(np.zeros((batch_size, self.num_go_terms)), dtype=tf.float32)\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F39OLyweenCG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "438fdb3d-e2fd-4c7c-afbd-20804c964379"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total proteins in JSON: 12632\n",
            "Proteins with latent representations: 10105\n",
            "Final dataset size: 10105\n",
            "Total proteins in JSON: 12632\n",
            "Proteins with latent representations: 1263\n",
            "Final dataset size: 1263\n",
            "Debugging first batch...\n",
            "Batch inputs shapes:\n",
            "  dpseq: (32, 1024, 100)\n",
            "    NaN: False, Inf: False\n",
            "    Range: [0.000000, 0.300855]\n",
            "  coords: (32, 1024, 3, 3)\n",
            "    NaN: False, Inf: False\n",
            "    Range: [-102.825996, 78.005997]\n",
            "  padding_mask: (32, 1024)\n",
            "    NaN: False, Inf: False\n",
            "    Range: [0.000000, 1.000000]\n",
            "Labels shape: (32, 10236)\n",
            "Labels sum per sample: [ 48. 106.   4.  62.  74.   4.  60. 120.  26. 199.  93.  49. 184.  17.\n",
            "  86.  46.  20. 103.  59.   4.  26. 100.  39. 109.  43.  37.  18.  10.\n",
            "  55.  67.   4.  53.]\n",
            "Labels NaN: False\n",
            "Testing model prediction...\n",
            "Prediction shape: (32, 10236)\n",
            "Prediction range: [0.423007, 0.573793]\n",
            "Prediction NaN: False\n",
            "Starting training...\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0: loss=0.694532\n",
            "\u001b[1m 10/316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m47s\u001b[0m 155ms/step - binary_accuracy: 0.5504 - loss: 0.6892Batch 10: loss=0.682360\n",
            "\u001b[1m 20/316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m45s\u001b[0m 154ms/step - binary_accuracy: 0.6103 - loss: 0.6828Batch 20: loss=0.668966\n",
            "\u001b[1m 30/316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m44s\u001b[0m 154ms/step - binary_accuracy: 0.6608 - loss: 0.6762Batch 30: loss=0.655498\n",
            "\u001b[1m 40/316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m42s\u001b[0m 154ms/step - binary_accuracy: 0.7010 - loss: 0.6695Batch 40: loss=0.641847\n",
            "\u001b[1m 50/316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m41s\u001b[0m 155ms/step - binary_accuracy: 0.7326 - loss: 0.6627Batch 50: loss=0.628493\n",
            "\u001b[1m 60/316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 157ms/step - binary_accuracy: 0.7578 - loss: 0.6560Batch 60: loss=0.615245\n",
            "\u001b[1m 70/316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m38s\u001b[0m 158ms/step - binary_accuracy: 0.7782 - loss: 0.6494Batch 70: loss=0.602141\n",
            "\u001b[1m 80/316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m37s\u001b[0m 158ms/step - binary_accuracy: 0.7950 - loss: 0.6427Batch 80: loss=0.589580\n",
            "\u001b[1m 90/316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m35s\u001b[0m 158ms/step - binary_accuracy: 0.8092 - loss: 0.6362Batch 90: loss=0.577359\n",
            "\u001b[1m100/316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m34s\u001b[0m 158ms/step - binary_accuracy: 0.8213 - loss: 0.6298Batch 100: loss=0.565523\n",
            "\u001b[1m110/316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m32s\u001b[0m 158ms/step - binary_accuracy: 0.8317 - loss: 0.6235Batch 110: loss=0.554061\n",
            "\u001b[1m120/316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m30s\u001b[0m 158ms/step - binary_accuracy: 0.8409 - loss: 0.6173Batch 120: loss=0.542960\n",
            "\u001b[1m130/316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m29s\u001b[0m 158ms/step - binary_accuracy: 0.8489 - loss: 0.6112Batch 130: loss=0.532147\n",
            "\u001b[1m140/316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m27s\u001b[0m 158ms/step - binary_accuracy: 0.8560 - loss: 0.6052Batch 140: loss=0.521639\n",
            "\u001b[1m150/316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 158ms/step - binary_accuracy: 0.8624 - loss: 0.5993Batch 150: loss=0.511529\n",
            "\u001b[1m160/316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 159ms/step - binary_accuracy: 0.8682 - loss: 0.5936Batch 160: loss=0.501629\n",
            "\u001b[1m170/316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 159ms/step - binary_accuracy: 0.8735 - loss: 0.5879Batch 170: loss=0.492211\n",
            "\u001b[1m180/316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 158ms/step - binary_accuracy: 0.8782 - loss: 0.5824Batch 180: loss=0.483013\n",
            "\u001b[1m190/316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 158ms/step - binary_accuracy: 0.8826 - loss: 0.5769Batch 190: loss=0.474063\n",
            "\u001b[1m200/316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 158ms/step - binary_accuracy: 0.8866 - loss: 0.5716Batch 200: loss=0.465362\n",
            "\u001b[1m210/316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 158ms/step - binary_accuracy: 0.8903 - loss: 0.5663Batch 210: loss=0.456918\n",
            "\u001b[1m220/316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 158ms/step - binary_accuracy: 0.8937 - loss: 0.5612Batch 220: loss=0.448844\n",
            "\u001b[1m230/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 159ms/step - binary_accuracy: 0.8969 - loss: 0.5562Batch 230: loss=0.440991\n",
            "\u001b[1m240/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m12s\u001b[0m 159ms/step - binary_accuracy: 0.8999 - loss: 0.5512Batch 240: loss=0.433349\n",
            "\u001b[1m250/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m10s\u001b[0m 159ms/step - binary_accuracy: 0.9027 - loss: 0.5464Batch 250: loss=0.425952\n",
            "\u001b[1m260/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - binary_accuracy: 0.9053 - loss: 0.5416Batch 260: loss=0.418764\n",
            "\u001b[1m270/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m7s\u001b[0m 158ms/step - binary_accuracy: 0.9077 - loss: 0.5369Batch 270: loss=0.411764\n",
            "\u001b[1m280/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m5s\u001b[0m 158ms/step - binary_accuracy: 0.9100 - loss: 0.5324Batch 280: loss=0.405181\n",
            "\u001b[1m290/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m5s\u001b[0m 211ms/step - binary_accuracy: 0.9122 - loss: 0.5279Batch 290: loss=0.398593\n",
            "\u001b[1m300/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m3s\u001b[0m 209ms/step - binary_accuracy: 0.9142 - loss: 0.5235Batch 300: loss=0.392147\n",
            "\u001b[1m310/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 208ms/step - binary_accuracy: 0.9161 - loss: 0.5191Batch 310: loss=0.385928\n",
            "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 230ms/step - binary_accuracy: 0.9174 - loss: 0.5162 - val_binary_accuracy: 0.9943 - val_loss: 0.1916 - learning_rate: 1.0000e-04\n",
            "Epoch 2/5\n",
            "Batch 0: loss=0.191023\n",
            "\u001b[1m 10/316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m48s\u001b[0m 158ms/step - binary_accuracy: 0.9944 - loss: 0.1903Batch 10: loss=0.190389\n",
            "\u001b[1m 20/316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m47s\u001b[0m 160ms/step - binary_accuracy: 0.9942 - loss: 0.1895Batch 20: loss=0.186671\n",
            "\u001b[1m 30/316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m46s\u001b[0m 161ms/step - binary_accuracy: 0.9942 - loss: 0.1881Batch 30: loss=0.183682\n",
            "\u001b[1m 40/316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m44s\u001b[0m 161ms/step - binary_accuracy: 0.9942 - loss: 0.1866Batch 40: loss=0.180589\n",
            "\u001b[1m 50/316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m42s\u001b[0m 160ms/step - binary_accuracy: 0.9941 - loss: 0.1852Batch 50: loss=0.177509\n",
            "\u001b[1m 60/316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 160ms/step - binary_accuracy: 0.9941 - loss: 0.1837Batch 60: loss=0.174748\n",
            "\u001b[1m 70/316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m39s\u001b[0m 160ms/step - binary_accuracy: 0.9941 - loss: 0.1822Batch 70: loss=0.172070\n",
            "\u001b[1m 80/316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m37s\u001b[0m 159ms/step - binary_accuracy: 0.9941 - loss: 0.1808Batch 80: loss=0.169411\n",
            "\u001b[1m 90/316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m35s\u001b[0m 159ms/step - binary_accuracy: 0.9942 - loss: 0.1794Batch 90: loss=0.166913\n",
            "\u001b[1m100/316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m34s\u001b[0m 159ms/step - binary_accuracy: 0.9942 - loss: 0.1781Batch 100: loss=0.164516\n",
            "\u001b[1m110/316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m32s\u001b[0m 160ms/step - binary_accuracy: 0.9942 - loss: 0.1767Batch 110: loss=0.162097\n",
            "\u001b[1m120/316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m31s\u001b[0m 160ms/step - binary_accuracy: 0.9942 - loss: 0.1754Batch 120: loss=0.159854\n",
            "\u001b[1m130/316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m29s\u001b[0m 160ms/step - binary_accuracy: 0.9942 - loss: 0.1741Batch 130: loss=0.157531\n",
            "\u001b[1m140/316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m28s\u001b[0m 160ms/step - binary_accuracy: 0.9942 - loss: 0.1729Batch 140: loss=0.155349\n",
            "\u001b[1m150/316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 160ms/step - binary_accuracy: 0.9942 - loss: 0.1717Batch 150: loss=0.153333\n",
            "\u001b[1m160/316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 160ms/step - binary_accuracy: 0.9942 - loss: 0.1705Batch 160: loss=0.151332\n",
            "\u001b[1m170/316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 160ms/step - binary_accuracy: 0.9942 - loss: 0.1693Batch 170: loss=0.149381\n",
            "\u001b[1m180/316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 160ms/step - binary_accuracy: 0.9942 - loss: 0.1681Batch 180: loss=0.147476\n",
            "\u001b[1m190/316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 161ms/step - binary_accuracy: 0.9942 - loss: 0.1670Batch 190: loss=0.145579\n",
            "\u001b[1m200/316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 161ms/step - binary_accuracy: 0.9942 - loss: 0.1659Batch 200: loss=0.143781\n",
            "\u001b[1m210/316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 161ms/step - binary_accuracy: 0.9942 - loss: 0.1648Batch 210: loss=0.141963\n",
            "\u001b[1m220/316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 161ms/step - binary_accuracy: 0.9942 - loss: 0.1637Batch 220: loss=0.140253\n",
            "\u001b[1m230/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 161ms/step - binary_accuracy: 0.9942 - loss: 0.1627Batch 230: loss=0.138552\n",
            "\u001b[1m240/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m12s\u001b[0m 161ms/step - binary_accuracy: 0.9942 - loss: 0.1616Batch 240: loss=0.136959\n",
            "\u001b[1m250/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m10s\u001b[0m 161ms/step - binary_accuracy: 0.9942 - loss: 0.1606Batch 250: loss=0.135333\n",
            "\u001b[1m260/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m8s\u001b[0m 161ms/step - binary_accuracy: 0.9942 - loss: 0.1596Batch 260: loss=0.133776\n",
            "\u001b[1m270/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - binary_accuracy: 0.9942 - loss: 0.1586Batch 270: loss=0.132288\n",
            "\u001b[1m280/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m5s\u001b[0m 161ms/step - binary_accuracy: 0.9942 - loss: 0.1577Batch 280: loss=0.130844\n",
            "\u001b[1m290/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m4s\u001b[0m 161ms/step - binary_accuracy: 0.9942 - loss: 0.1567Batch 290: loss=0.129458\n",
            "\u001b[1m300/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 161ms/step - binary_accuracy: 0.9942 - loss: 0.1558Batch 300: loss=0.128075\n",
            "\u001b[1m310/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - binary_accuracy: 0.9942 - loss: 0.1549Batch 310: loss=0.126758\n",
            "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 172ms/step - binary_accuracy: 0.9942 - loss: 0.1542 - val_binary_accuracy: 0.9943 - val_loss: 0.0830 - learning_rate: 1.0000e-04\n",
            "Epoch 3/5\n",
            "Batch 0: loss=0.081113\n",
            "\u001b[1m 10/316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m48s\u001b[0m 158ms/step - binary_accuracy: 0.9941 - loss: 0.0824Batch 10: loss=0.082724\n",
            "\u001b[1m 20/316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m47s\u001b[0m 161ms/step - binary_accuracy: 0.9941 - loss: 0.0823Batch 20: loss=0.081744\n",
            "\u001b[1m 30/316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m46s\u001b[0m 163ms/step - binary_accuracy: 0.9942 - loss: 0.0821Batch 30: loss=0.081333\n",
            "\u001b[1m 40/316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m44s\u001b[0m 162ms/step - binary_accuracy: 0.9942 - loss: 0.0818Batch 40: loss=0.080764\n",
            "\u001b[1m 50/316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m42s\u001b[0m 161ms/step - binary_accuracy: 0.9942 - loss: 0.0815Batch 50: loss=0.079670\n",
            "\u001b[1m 60/316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m41s\u001b[0m 161ms/step - binary_accuracy: 0.9942 - loss: 0.0811Batch 60: loss=0.078877\n",
            "\u001b[1m 70/316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m39s\u001b[0m 160ms/step - binary_accuracy: 0.9942 - loss: 0.0808Batch 70: loss=0.078210\n",
            "\u001b[1m 80/316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m37s\u001b[0m 160ms/step - binary_accuracy: 0.9942 - loss: 0.0804Batch 80: loss=0.077363\n",
            "\u001b[1m 90/316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m36s\u001b[0m 160ms/step - binary_accuracy: 0.9942 - loss: 0.0800Batch 90: loss=0.076767\n",
            "\u001b[1m100/316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m34s\u001b[0m 159ms/step - binary_accuracy: 0.9942 - loss: 0.0797Batch 100: loss=0.076001\n",
            "\u001b[1m110/316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m32s\u001b[0m 160ms/step - binary_accuracy: 0.9942 - loss: 0.0793Batch 110: loss=0.075407\n",
            "\u001b[1m120/316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m31s\u001b[0m 161ms/step - binary_accuracy: 0.9942 - loss: 0.0790Batch 120: loss=0.074786\n",
            "\u001b[1m130/316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m29s\u001b[0m 160ms/step - binary_accuracy: 0.9942 - loss: 0.0786Batch 130: loss=0.074133\n",
            "\u001b[1m140/316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m28s\u001b[0m 160ms/step - binary_accuracy: 0.9942 - loss: 0.0783Batch 140: loss=0.073650\n",
            "\u001b[1m150/316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 160ms/step - binary_accuracy: 0.9942 - loss: 0.0780Batch 150: loss=0.073190\n",
            "\u001b[1m160/316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 159ms/step - binary_accuracy: 0.9942 - loss: 0.0776Batch 160: loss=0.072589\n",
            "\u001b[1m170/316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 159ms/step - binary_accuracy: 0.9942 - loss: 0.0773Batch 170: loss=0.072022\n",
            "\u001b[1m180/316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 159ms/step - binary_accuracy: 0.9942 - loss: 0.0770Batch 180: loss=0.071445\n",
            "\u001b[1m190/316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 159ms/step - binary_accuracy: 0.9942 - loss: 0.0767Batch 190: loss=0.070879\n",
            "\u001b[1m200/316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 159ms/step - binary_accuracy: 0.9942 - loss: 0.0764Batch 200: loss=0.070384\n",
            "\u001b[1m210/316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 160ms/step - binary_accuracy: 0.9942 - loss: 0.0761Batch 210: loss=0.069921\n",
            "\u001b[1m220/316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 160ms/step - binary_accuracy: 0.9942 - loss: 0.0758Batch 220: loss=0.069385\n",
            "\u001b[1m230/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 160ms/step - binary_accuracy: 0.9942 - loss: 0.0755Batch 230: loss=0.068933\n",
            "\u001b[1m240/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m12s\u001b[0m 160ms/step - binary_accuracy: 0.9942 - loss: 0.0752Batch 240: loss=0.068413\n",
            "\u001b[1m250/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m10s\u001b[0m 160ms/step - binary_accuracy: 0.9942 - loss: 0.0750Batch 250: loss=0.067938\n",
            "\u001b[1m260/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - binary_accuracy: 0.9942 - loss: 0.0747Batch 260: loss=0.067442\n",
            "\u001b[1m270/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m7s\u001b[0m 159ms/step - binary_accuracy: 0.9942 - loss: 0.0744Batch 270: loss=0.066978\n",
            "\u001b[1m280/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m5s\u001b[0m 160ms/step - binary_accuracy: 0.9942 - loss: 0.0741Batch 280: loss=0.066527\n",
            "\u001b[1m290/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - binary_accuracy: 0.9942 - loss: 0.0739Batch 290: loss=0.066044\n",
            "\u001b[1m300/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 160ms/step - binary_accuracy: 0.9942 - loss: 0.0736Batch 300: loss=0.065580\n",
            "\u001b[1m310/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - binary_accuracy: 0.9942 - loss: 0.0733Batch 310: loss=0.065185\n",
            "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 171ms/step - binary_accuracy: 0.9942 - loss: 0.0732 - val_binary_accuracy: 0.9943 - val_loss: 0.0509 - learning_rate: 1.0000e-04\n",
            "Epoch 4/5\n",
            "Batch 0: loss=0.055529\n",
            "\u001b[1m 10/316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m49s\u001b[0m 162ms/step - binary_accuracy: 0.9939 - loss: 0.0523Batch 10: loss=0.051138\n",
            "\u001b[1m 20/316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m47s\u001b[0m 159ms/step - binary_accuracy: 0.9940 - loss: 0.0517Batch 20: loss=0.051028\n",
            "\u001b[1m 30/316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m46s\u001b[0m 163ms/step - binary_accuracy: 0.9940 - loss: 0.0515Batch 30: loss=0.051122\n",
            "\u001b[1m 40/316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m45s\u001b[0m 164ms/step - binary_accuracy: 0.9941 - loss: 0.0513Batch 40: loss=0.050379\n",
            "\u001b[1m 50/316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m43s\u001b[0m 163ms/step - binary_accuracy: 0.9941 - loss: 0.0511Batch 50: loss=0.050111\n",
            "\u001b[1m 60/316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m41s\u001b[0m 162ms/step - binary_accuracy: 0.9941 - loss: 0.0509Batch 60: loss=0.049752\n",
            "\u001b[1m 70/316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m39s\u001b[0m 161ms/step - binary_accuracy: 0.9941 - loss: 0.0507Batch 70: loss=0.049476\n",
            "\u001b[1m 80/316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m37s\u001b[0m 161ms/step - binary_accuracy: 0.9941 - loss: 0.0506Batch 80: loss=0.049239\n",
            "\u001b[1m 90/316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m36s\u001b[0m 161ms/step - binary_accuracy: 0.9942 - loss: 0.0504Batch 90: loss=0.048860\n",
            "\u001b[1m100/316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m34s\u001b[0m 160ms/step - binary_accuracy: 0.9942 - loss: 0.0502Batch 100: loss=0.048500\n",
            "\u001b[1m110/316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m33s\u001b[0m 160ms/step - binary_accuracy: 0.9942 - loss: 0.0501Batch 110: loss=0.048408\n",
            "\u001b[1m120/316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m31s\u001b[0m 161ms/step - binary_accuracy: 0.9942 - loss: 0.0499Batch 120: loss=0.048171\n",
            "\u001b[1m130/316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m30s\u001b[0m 161ms/step - binary_accuracy: 0.9942 - loss: 0.0498Batch 130: loss=0.048013\n",
            "\u001b[1m140/316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m28s\u001b[0m 161ms/step - binary_accuracy: 0.9942 - loss: 0.0496Batch 140: loss=0.047750\n",
            "\u001b[1m150/316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 161ms/step - binary_accuracy: 0.9942 - loss: 0.0495Batch 150: loss=0.047653\n",
            "\u001b[1m160/316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 161ms/step - binary_accuracy: 0.9942 - loss: 0.0494Batch 160: loss=0.047462\n",
            "\u001b[1m170/316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 161ms/step - binary_accuracy: 0.9942 - loss: 0.0493Batch 170: loss=0.047250\n",
            "\u001b[1m180/316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 160ms/step - binary_accuracy: 0.9942 - loss: 0.0492Batch 180: loss=0.047113\n",
            "\u001b[1m190/316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 160ms/step - binary_accuracy: 0.9942 - loss: 0.0491Batch 190: loss=0.046934\n",
            "\u001b[1m200/316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 161ms/step - binary_accuracy: 0.9942 - loss: 0.0489Batch 200: loss=0.046673\n",
            "\u001b[1m210/316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 161ms/step - binary_accuracy: 0.9942 - loss: 0.0488Batch 210: loss=0.046449\n",
            "\u001b[1m220/316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 161ms/step - binary_accuracy: 0.9942 - loss: 0.0487Batch 220: loss=0.046185\n",
            "\u001b[1m230/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 161ms/step - binary_accuracy: 0.9942 - loss: 0.0486Batch 230: loss=0.045989\n",
            "\u001b[1m240/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m12s\u001b[0m 161ms/step - binary_accuracy: 0.9942 - loss: 0.0485Batch 240: loss=0.045809\n",
            "\u001b[1m250/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m10s\u001b[0m 161ms/step - binary_accuracy: 0.9942 - loss: 0.0484Batch 250: loss=0.045575\n",
            "\u001b[1m260/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m8s\u001b[0m 160ms/step - binary_accuracy: 0.9942 - loss: 0.0483Batch 260: loss=0.045373\n",
            "\u001b[1m270/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m7s\u001b[0m 160ms/step - binary_accuracy: 0.9942 - loss: 0.0482Batch 270: loss=0.045180\n",
            "\u001b[1m280/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m5s\u001b[0m 160ms/step - binary_accuracy: 0.9942 - loss: 0.0480Batch 280: loss=0.045001\n",
            "\u001b[1m290/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m4s\u001b[0m 161ms/step - binary_accuracy: 0.9942 - loss: 0.0479Batch 290: loss=0.044809\n",
            "\u001b[1m300/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 161ms/step - binary_accuracy: 0.9942 - loss: 0.0478Batch 300: loss=0.044604\n",
            "\u001b[1m310/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - binary_accuracy: 0.9942 - loss: 0.0477Batch 310: loss=0.044400\n",
            "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 177ms/step - binary_accuracy: 0.9942 - loss: 0.0477 - val_binary_accuracy: 0.9943 - val_loss: 0.0381 - learning_rate: 1.0000e-04\n",
            "Epoch 5/5\n",
            "Batch 0: loss=0.039641\n",
            "\u001b[1m 10/316\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m48s\u001b[0m 158ms/step - binary_accuracy: 0.9947 - loss: 0.0374Batch 10: loss=0.036938\n",
            "\u001b[1m 20/316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m47s\u001b[0m 161ms/step - binary_accuracy: 0.9947 - loss: 0.0372Batch 20: loss=0.037508\n",
            "\u001b[1m 30/316\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m46s\u001b[0m 162ms/step - binary_accuracy: 0.9946 - loss: 0.0373Batch 30: loss=0.037531\n",
            "\u001b[1m 40/316\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m44s\u001b[0m 161ms/step - binary_accuracy: 0.9946 - loss: 0.0374Batch 40: loss=0.037477\n",
            "\u001b[1m 50/316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m42s\u001b[0m 160ms/step - binary_accuracy: 0.9946 - loss: 0.0374Batch 50: loss=0.037614\n",
            "\u001b[1m 60/316\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 159ms/step - binary_accuracy: 0.9945 - loss: 0.0374Batch 60: loss=0.037436\n",
            "\u001b[1m 70/316\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m39s\u001b[0m 159ms/step - binary_accuracy: 0.9945 - loss: 0.0374Batch 70: loss=0.037408\n",
            "\u001b[1m 80/316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m37s\u001b[0m 159ms/step - binary_accuracy: 0.9945 - loss: 0.0374Batch 80: loss=0.037596\n",
            "\u001b[1m 90/316\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m35s\u001b[0m 158ms/step - binary_accuracy: 0.9945 - loss: 0.0374Batch 90: loss=0.037461\n",
            "\u001b[1m100/316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m34s\u001b[0m 159ms/step - binary_accuracy: 0.9944 - loss: 0.0374Batch 100: loss=0.037234\n",
            "\u001b[1m110/316\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m32s\u001b[0m 159ms/step - binary_accuracy: 0.9944 - loss: 0.0374Batch 110: loss=0.037103\n",
            "\u001b[1m120/316\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m31s\u001b[0m 160ms/step - binary_accuracy: 0.9944 - loss: 0.0374Batch 120: loss=0.037083\n",
            "\u001b[1m130/316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m29s\u001b[0m 159ms/step - binary_accuracy: 0.9944 - loss: 0.0374Batch 130: loss=0.036980\n",
            "\u001b[1m140/316\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m28s\u001b[0m 159ms/step - binary_accuracy: 0.9944 - loss: 0.0373Batch 140: loss=0.036845\n",
            "\u001b[1m150/316\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 159ms/step - binary_accuracy: 0.9944 - loss: 0.0373Batch 150: loss=0.036775\n",
            "\u001b[1m160/316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 159ms/step - binary_accuracy: 0.9944 - loss: 0.0373Batch 160: loss=0.036686\n",
            "\u001b[1m170/316\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 159ms/step - binary_accuracy: 0.9944 - loss: 0.0372Batch 170: loss=0.036574\n",
            "\u001b[1m180/316\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 159ms/step - binary_accuracy: 0.9943 - loss: 0.0372Batch 180: loss=0.036462\n",
            "\u001b[1m190/316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 159ms/step - binary_accuracy: 0.9943 - loss: 0.0371Batch 190: loss=0.036418\n",
            "\u001b[1m200/316\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 159ms/step - binary_accuracy: 0.9943 - loss: 0.0371Batch 200: loss=0.036315\n",
            "\u001b[1m210/316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 159ms/step - binary_accuracy: 0.9943 - loss: 0.0371Batch 210: loss=0.036240\n",
            "\u001b[1m220/316\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 159ms/step - binary_accuracy: 0.9943 - loss: 0.0370Batch 220: loss=0.036101\n",
            "\u001b[1m230/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 159ms/step - binary_accuracy: 0.9943 - loss: 0.0370Batch 230: loss=0.035957\n",
            "\u001b[1m240/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m12s\u001b[0m 159ms/step - binary_accuracy: 0.9943 - loss: 0.0369Batch 240: loss=0.035885\n",
            "\u001b[1m250/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m10s\u001b[0m 159ms/step - binary_accuracy: 0.9943 - loss: 0.0369Batch 250: loss=0.035791\n",
            "\u001b[1m260/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m8s\u001b[0m 159ms/step - binary_accuracy: 0.9943 - loss: 0.0369Batch 260: loss=0.035669\n",
            "\u001b[1m270/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m7s\u001b[0m 159ms/step - binary_accuracy: 0.9943 - loss: 0.0368Batch 270: loss=0.035577\n",
            "\u001b[1m280/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m5s\u001b[0m 159ms/step - binary_accuracy: 0.9943 - loss: 0.0368Batch 280: loss=0.035500\n",
            "\u001b[1m290/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - binary_accuracy: 0.9943 - loss: 0.0367Batch 290: loss=0.035370\n",
            "\u001b[1m300/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 159ms/step - binary_accuracy: 0.9943 - loss: 0.0367Batch 300: loss=0.035338\n",
            "\u001b[1m310/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - binary_accuracy: 0.9943 - loss: 0.0366Batch 310: loss=0.035250\n",
            "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 171ms/step - binary_accuracy: 0.9943 - loss: 0.0366 - val_binary_accuracy: 0.9943 - val_loss: 0.0319 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 5.\n",
            "Training completed successfully!\n"
          ]
        }
      ],
      "source": [
        "#@title Structural model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model, Input\n",
        "from tensorflow.keras.layers import Lambda\n",
        "import numpy as np\n",
        "import json\n",
        "import pandas as pd\n",
        "import ast\n",
        "\n",
        "# Custom layers for your model\n",
        "class PrepareAttentionMask(layers.Layer):\n",
        "    \"\"\"Custom layer to prepare a boolean padding mask for MultiHeadAttention.\"\"\"\n",
        "    def call(self, inputs):\n",
        "        boolean_mask = tf.cast(1 - inputs, tf.bool)\n",
        "        expanded_mask = boolean_mask[:, tf.newaxis, tf.newaxis, :]\n",
        "        return expanded_mask\n",
        "\n",
        "class PreparePoolingMask(layers.Layer):\n",
        "    \"\"\"Custom layer to prepare a boolean padding mask for GlobalAveragePooling1D.\"\"\"\n",
        "    def call(self, inputs):\n",
        "        boolean_mask = tf.cast(1 - inputs, tf.bool)\n",
        "        return boolean_mask\n",
        "\n",
        "class SafeClipLayer(layers.Layer):\n",
        "    \"\"\"Improved clipping layer with gradient-safe operations\"\"\"\n",
        "    def __init__(self, clip_value_min=-10.0, clip_value_max=10.0, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.clip_value_min = clip_value_min\n",
        "        self.clip_value_max = clip_value_max\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # First remove any inf/nan values\n",
        "        inputs = tf.where(tf.math.is_finite(inputs), inputs, 0.0)\n",
        "        # Then clip to prevent extreme values\n",
        "        #clip_val = tf.clip_by_value(inputs, self.clip_value_min, self.clip_value_max)\n",
        "        return tf.clip_by_value(inputs, self.clip_value_min, self.clip_value_max)\n",
        "        #return tf.debugging.check_numerics(clip_val, \"Clip mask have NaN/Inf\")\n",
        "\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            'clip_value_min': self.clip_value_min,\n",
        "            'clip_value_max': self.clip_value_max\n",
        "        })\n",
        "        return config\n",
        "\n",
        "class DihedralLayer(tf.keras.layers.Layer):\n",
        "    \"\"\"Layer for computing dihedral angles from protein backbone coordinates (N, CA, C)\"\"\"\n",
        "\n",
        "    def __init__(self, eps=1e-7, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.eps = eps\n",
        "\n",
        "    def call(self, coords):\n",
        "        # coords shape: (batch_size, seq_len, 3, 3) - atoms N, CA, C\n",
        "        # Step 1: Reshape to (batch_size, 3 * seq_len, 3)\n",
        "        batch_size = tf.shape(coords)[0]\n",
        "        seq_len = tf.shape(coords)[1]\n",
        "        coords_flat = tf.reshape(coords[:, :, :3, :], [batch_size, seq_len * 3, 3])\n",
        "\n",
        "        # Step 2: Compute link vectors (bond directions)\n",
        "        dX = coords_flat[:, 1:, :] - coords_flat[:, :-1, :]\n",
        "\n",
        "        # Step 3: Normalize bond vectors\n",
        "        U = tf.math.l2_normalize(dX + self.eps, axis=-1)\n",
        "\n",
        "        # Step 4: Get consecutive vectors\n",
        "        u_2 = U[:, :-2, :]\n",
        "        u_1 = U[:, 1:-1, :]\n",
        "        u_0 = U[:, 2:, :]\n",
        "\n",
        "        # Step 5: Compute normals to planes formed by the vectors\n",
        "        n_2 = tf.linalg.cross(u_2, u_1)\n",
        "        n_1 = tf.linalg.cross(u_1, u_0)\n",
        "\n",
        "        # Step 6: Normalize the normals\n",
        "        n_2 = tf.math.l2_normalize(n_2 + self.eps, axis=-1)\n",
        "        n_1 = tf.math.l2_normalize(n_1 + self.eps, axis=-1)\n",
        "\n",
        "        # Step 7: Compute cosine and angle sign\n",
        "        cosD = tf.reduce_sum(n_2 * n_1, axis=-1)\n",
        "        cosD = tf.clip_by_value(cosD, -1.0 + self.eps, 1.0 - self.eps)\n",
        "\n",
        "        angle = tf.acos(cosD)\n",
        "        sign = tf.sign(tf.reduce_sum(u_2 * n_1, axis=-1))\n",
        "        D = sign * angle  # Dihedral angle\n",
        "\n",
        "        # Step 8: Pad D to align with residues (phi, psi, omega)\n",
        "        D_padded = tf.pad(D, [[0, 0], [1, 2]], mode='CONSTANT')  # (batch, 3*res-3 + 3) = 3*res\n",
        "        D_reshaped = tf.reshape(D_padded, [batch_size, seq_len, 3])\n",
        "\n",
        "        # Step 9: Convert to circular features\n",
        "        dihedral_features = tf.concat([\n",
        "            tf.math.cos(D_reshaped),\n",
        "            tf.math.sin(D_reshaped)\n",
        "        ], axis=-1)  # shape: (batch_size, seq_len, 6)\n",
        "\n",
        "        return dihedral_features\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0], input_shape[1], 6)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({'eps': self.eps})\n",
        "        return config\n",
        "\n",
        "def masked_mean(tensor, mask):\n",
        "    mask = tf.cast(mask, tf.float32)\n",
        "    mask = tf.expand_dims(mask, axis=-1)  # (batch, seq_len, 1)\n",
        "    tensor *= mask\n",
        "    summed = tf.reduce_sum(tensor, axis=1)\n",
        "    mask_sum = tf.reduce_sum(mask, axis=1)\n",
        "    mask_sum = tf.where(mask_sum == 0, tf.ones_like(mask_sum), mask_sum)  # prevent divide-by-zero\n",
        "    return summed / mask_sum\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def build_model_transformer(\n",
        "    esm_dim,\n",
        "    embed_dim,\n",
        "    num_layers,\n",
        "    num_heads,\n",
        "    num_go_terms,\n",
        "    dropout_rate=0.1,\n",
        "    max_seq_len=1024 # This is now fixed in the data loader\n",
        "):\n",
        "    # Inputs\n",
        "    dpseq_in = Input(shape=(max_seq_len, esm_dim), name=\"dpseq\") # Use fixed max_seq_len\n",
        "    coords_in = Input(shape=(max_seq_len, 3, 3), name=\"coords\") # Use fixed max_seq_len\n",
        "    padding_mask_in = Input(shape=(max_seq_len,), dtype=tf.float32, name=\"padding_mask\") # Use fixed max_seq_len\n",
        "\n",
        "    # ESM Projection with improved initialization and normalization\n",
        "    dpseq_proj = layers.Dense(\n",
        "        embed_dim,\n",
        "        activation=None,  # Apply activation separately\n",
        "        kernel_initializer='glorot_uniform',\n",
        "        bias_initializer='zeros'\n",
        "    )(dpseq_in)\n",
        "    dpseq_proj = Lambda(lambda x: tf.debugging.check_numerics(x, message=\"NaNs in dpseq_proj after dense layer\"))(dpseq_proj)\n",
        "    dpseq_proj = layers.LayerNormalization()(dpseq_proj)\n",
        "    dpseq_proj = layers.Activation('gelu')(dpseq_proj)\n",
        "    dpseq_proj = Lambda(lambda x: tf.debugging.check_numerics(x, message=\"NaNs in dpseq_proj before SafeClipLayer\"))(dpseq_proj)\n",
        "    dpseq_proj = SafeClipLayer(clip_value_min=-5.0, clip_value_max=5.0)(dpseq_proj)\n",
        "\n",
        "    # Dihedral Embedding with improved stability\n",
        "    dihedral_layer = DihedralLayer(eps=1e-7, name=\"dihedral_layer\")\n",
        "    dihedral_features = dihedral_layer(coords_in)\n",
        "    dihedral_emb = layers.Dense(\n",
        "        embed_dim,\n",
        "        activation='tanh',\n",
        "        name='dihedral_projection'\n",
        "    )(dihedral_features)\n",
        "    dihedral_emb = Lambda(lambda x: tf.debugging.check_numerics(x, message=\"NaNs in dihedral_emb before dense layer\"))(dihedral_emb)\n",
        "    dihedral_emb = layers.LayerNormalization(epsilon=1e-6)(dihedral_emb)\n",
        "    dihedral_emb = SafeClipLayer(clip_value_min=-5.0, clip_value_max=5.0)(dihedral_emb)\n",
        "    dihedral_emb = Lambda(lambda x: tf.debugging.check_numerics(x, message=\"NaNs in dihedral_emb after SafeClipLayer\"))(dihedral_emb)\n",
        "\n",
        "    # Combine embeddings with residual connection and normalization\n",
        "    embed = layers.Add()([dihedral_emb, dpseq_proj])\n",
        "    embed = layers.LayerNormalization(epsilon=1e-6)(embed)  # Larger epsilon for stability\n",
        "    embed = layers.Dropout(dropout_rate)(embed)\n",
        "    embed = Lambda(lambda x: tf.debugging.check_numerics(x, message=\"NaNs in embed after dropout\"))(embed)\n",
        "\n",
        "    # Prepare attention mask\n",
        "    attention_mask = PrepareAttentionMask()(padding_mask_in)\n",
        "\n",
        "    # Transformer Encoder with improved stability\n",
        "    x = embed\n",
        "    for i in range(num_layers):\n",
        "        # Multi-Head Attention with proper normalization\n",
        "        attention_output = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads,\n",
        "            key_dim=embed_dim // num_heads,\n",
        "            dropout=dropout_rate,\n",
        "            kernel_initializer='glorot_uniform'\n",
        "        )(x, x, attention_mask=attention_mask)\n",
        "\n",
        "        # Pre-norm residual connection\n",
        "        x_normed = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "        x = layers.Add()([x, layers.Dropout(dropout_rate)(attention_output)])\n",
        "\n",
        "        # Feed Forward Network with pre-normalization\n",
        "        x_normed = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "        ff_dim = embed_dim * 2\n",
        "        feed_forward_output = layers.Dense(\n",
        "            ff_dim,\n",
        "            activation=\"relu\",\n",
        "            kernel_initializer='glorot_uniform'\n",
        "        )(x_normed)\n",
        "        feed_forward_output = layers.Dropout(dropout_rate)(feed_forward_output)\n",
        "        feed_forward_output = layers.Dense(\n",
        "            embed_dim,\n",
        "            kernel_initializer='glorot_uniform'\n",
        "        )(feed_forward_output)\n",
        "\n",
        "        # Residual connection\n",
        "        x = layers.Add()([x, layers.Dropout(dropout_rate)(feed_forward_output)])\n",
        "\n",
        "    # Final layer normalization\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "    x = Lambda(lambda x: tf.debugging.check_numerics(x, message=\"NaNs in final layer normalization\"))(x)\n",
        "\n",
        "    # Global Average Pooling with mask\n",
        "    boolean_pooling_mask = PreparePoolingMask()(padding_mask_in)\n",
        "    pooled_output = Lambda(lambda args: masked_mean(args[0], args[1]), name=\"safe_masked_mean\")([x, boolean_pooling_mask])\n",
        "    #pooled_output = layers.GlobalAveragePooling1D()(x, mask=boolean_pooling_mask)\n",
        "    pooled_output = Lambda(lambda x: tf.debugging.check_numerics(x, message=\"NaNs in pooled_output before dense layer\"))(pooled_output)\n",
        "\n",
        "    # Additional processing layers with proper initialization\n",
        "    pooled_output = layers.Dense(\n",
        "        embed_dim // 2,\n",
        "        activation='relu',\n",
        "        kernel_initializer='glorot_uniform',\n",
        "        bias_initializer='zeros'\n",
        "    )(pooled_output)\n",
        "    pooled_output = layers.LayerNormalization(epsilon=1e-6)(pooled_output)\n",
        "    pooled_output = layers.Dropout(dropout_rate)(pooled_output)\n",
        "\n",
        "    # GO term prediction with careful initialization\n",
        "    go_terms_output = layers.Dense(\n",
        "        num_go_terms,\n",
        "        activation=\"sigmoid\",\n",
        "        name=\"go_terms_output\",\n",
        "        kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01),\n",
        "        bias_initializer='zeros'\n",
        "    )(pooled_output)\n",
        "\n",
        "    return Model(\n",
        "        inputs=[dpseq_in, coords_in, padding_mask_in],\n",
        "        outputs=go_terms_output,\n",
        "        name=\"gvp_transformer_encoder_with_go_output\"\n",
        "    )\n",
        "\n",
        "\n",
        "def setup_training_with_latent_space(json_data, train_latent_dict, val_latent_dict, go_term_vocabulary, go_term_to_index, num_go_terms, latent_dim=100, fixed_max_len=1024):\n",
        "    \"\"\"\n",
        "    Modified setup function that uses latent space representations and extracts\n",
        "    GO terms directly from the JSON structure file.\n",
        "\n",
        "    Args:\n",
        "        latent_representations_dict: Dictionary mapping protein_id -> latent_vector\n",
        "        latent_dim: Dimension of the latent space (default 100 for GlobalAveragePooling1D)\n",
        "        fixed_max_len: The fixed maximum sequence length to use for padding.\n",
        "    \"\"\"\n",
        "\n",
        "    # Create data loader\n",
        "    data_loader = JsonDataLoaderWithLatentSpace(\n",
        "        in_data=json_data,\n",
        "        batch_size=32,\n",
        "        go_term_vocabulary=go_term_vocabulary,\n",
        "        go_term_to_index=go_term_to_index,\n",
        "        latent_representations_dict=train_latent_dict,\n",
        "        latent_dim=latent_dim,\n",
        "        coords_mask_plddt_th=70.0,\n",
        "        fixed_max_len=fixed_max_len # Pass fixed_max_len to data loader\n",
        "    )\n",
        "\n",
        "    val_loader = JsonDataLoaderWithLatentSpace(\n",
        "        in_data=json_data,\n",
        "        batch_size=4,\n",
        "        go_term_vocabulary=go_term_vocabulary,\n",
        "        go_term_to_index=go_term_to_index,\n",
        "        latent_representations_dict=val_latent_dict,\n",
        "        latent_dim=latent_dim,\n",
        "        coords_mask_plddt_th=70.0,\n",
        "        fixed_max_len=fixed_max_len # Pass fixed_max_len to data loader\n",
        "    )\n",
        "\n",
        "    # Build model - you need to modify the esm_dim parameter to match your latent_dim\n",
        "    model = build_model_transformer(\n",
        "        esm_dim=latent_dim,  # Changed from 1280 to your latent dimension\n",
        "        embed_dim=120,\n",
        "        num_layers=2,\n",
        "        num_heads=4,\n",
        "        num_go_terms=num_go_terms,\n",
        "        dropout_rate=0.1,\n",
        "        max_seq_len=fixed_max_len # Pass fixed_max_len to model builder\n",
        "    )\n",
        "\n",
        "    # Custom optimizer with gradient clipping and lower learning rate\n",
        "    optimizer = tf.keras.optimizers.AdamW(\n",
        "        learning_rate=1e-4,  # Lower learning rate\n",
        "        #weight_decay=1e-4,   # Add weight decay\n",
        "        clipnorm=1.0,        # Aggressive gradient clipping\n",
        "        epsilon=1e-8         # Larger epsilon for numerical stability\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "        metrics=['binary_accuracy'],\n",
        "        run_eagerly=False  # Set to True for debugging\n",
        "    )\n",
        "\n",
        "    # Enhanced callbacks\n",
        "    callbacks = [\n",
        "        tf.keras.callbacks.EarlyStopping(\n",
        "            monitor='loss',\n",
        "            patience=5,\n",
        "            restore_best_weights=True,\n",
        "            verbose=1\n",
        "        ),\n",
        "        tf.keras.callbacks.ReduceLROnPlateau(\n",
        "            monitor='loss',\n",
        "            factor=0.5,\n",
        "            patience=3,\n",
        "            min_lr=1e-7,\n",
        "            verbose=1\n",
        "        ),\n",
        "        tf.keras.callbacks.TerminateOnNaN(),  # Stop training if NaN is encountered\n",
        "        tf.keras.callbacks.LambdaCallback(\n",
        "            on_batch_end=lambda batch, logs: print(f\"Batch {batch}: loss={logs.get('loss', 'N/A'):.6f}\")\n",
        "            if batch % 10 == 0 else None\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    return model, data_loader, callbacks, val_loader\n",
        "\n",
        "# Debug and validation functions\n",
        "def debug_model_inputs(data_loader, model):\n",
        "    \"\"\"Debug function to check for NaN/Inf values in data\"\"\"\n",
        "    print(\"Debugging first batch...\")\n",
        "    try:\n",
        "        batch_inputs, batch_labels = data_loader[0]\n",
        "\n",
        "        print(f\"Batch inputs shapes:\")\n",
        "        for key, value in batch_inputs.items():\n",
        "            print(f\"  {key}: {value.shape}\")\n",
        "            has_nan = tf.reduce_any(tf.math.is_nan(value))\n",
        "            has_inf = tf.reduce_any(tf.math.is_inf(value))\n",
        "            min_val = tf.reduce_min(value)\n",
        "            max_val = tf.reduce_max(value)\n",
        "            print(f\"    NaN: {has_nan}, Inf: {has_inf}\")\n",
        "            print(f\"    Range: [{min_val:.6f}, {max_val:.6f}]\")\n",
        "\n",
        "        print(f\"Labels shape: {batch_labels.shape}\")\n",
        "        print(f\"Labels sum per sample: {tf.reduce_sum(batch_labels, axis=1)}\")\n",
        "        print(f\"Labels NaN: {tf.reduce_any(tf.math.is_nan(batch_labels))}\")\n",
        "\n",
        "        # Test model prediction\n",
        "        print(\"Testing model prediction...\")\n",
        "        pred = model(batch_inputs, training=False)\n",
        "        print(f\"Prediction shape: {pred.shape}\")\n",
        "        print(f\"Prediction range: [{tf.reduce_min(pred):.6f}, {tf.reduce_max(pred):.6f}]\")\n",
        "        print(f\"Prediction NaN: {tf.reduce_any(tf.math.is_nan(pred))}\")\n",
        "\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in debugging: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return False\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Setup training\n",
        "    #json_data, train_ids, val_ids, test_ids = load_and_split_json(base_path + json_file_path)\n",
        "    # go_term_vocabulary, go_term_to_index, num_go_terms = extract_go_terms_from_json(json_data)\n",
        "    # x_train_dic, x_val_dic\n",
        "\n",
        "    # Use a fixed max_len when setting up the training\n",
        "    fixed_max_len = 1024\n",
        "    model, data_loader, callbacks, val_loader = setup_training_with_latent_space(json_data, x_train_dict, x_val_dict, go_term_vocabulary, go_term_to_index, num_go_terms, fixed_max_len=fixed_max_len)\n",
        "\n",
        "    # Debug first\n",
        "    if debug_model_inputs(data_loader, model):\n",
        "        print(\"Starting training...\")\n",
        "        try:\n",
        "            history = model.fit(\n",
        "                data_loader,\n",
        "                epochs=5,\n",
        "                callbacks=callbacks,\n",
        "                verbose=1,\n",
        "                validation_data=val_loader  # Add validation data if available\n",
        "            )\n",
        "            print(\"Training completed successfully!\")\n",
        "        except Exception as e:\n",
        "            print(f\"Training error: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "    else:\n",
        "        print(\"Debug failed, please check your data.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqj4Rlff_A1T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "66e81f03-8090-4405-d134-330149245d05"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"gvp_transformer_encoder_with_go_output\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gvp_transformer_encoder_with_go_output\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ coords (\u001b[38;5;33mInputLayer\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m3\u001b[0m,   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│                     │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dpseq (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m100\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dihedral_layer      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m6\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ coords[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mDihedralLayer\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m120\u001b[0m) │     \u001b[38;5;34m12,120\u001b[0m │ dpseq[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dihedral_projection │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m120\u001b[0m) │        \u001b[38;5;34m840\u001b[0m │ dihedral_layer[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lambda (\u001b[38;5;33mLambda\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m120\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lambda_2 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m120\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ dihedral_project… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m120\u001b[0m) │        \u001b[38;5;34m240\u001b[0m │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m120\u001b[0m) │        \u001b[38;5;34m240\u001b[0m │ lambda_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m120\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ safe_clip_layer_1   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m120\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mSafeClipLayer\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lambda_1 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m120\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ activation_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lambda_3 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m120\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ safe_clip_layer_… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ safe_clip_layer     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m120\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ lambda_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mSafeClipLayer\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add (\u001b[38;5;33mAdd\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m120\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ lambda_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
              "│                     │                   │            │ safe_clip_layer[\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m120\u001b[0m) │        \u001b[38;5;34m240\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m120\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ padding_mask        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lambda_4 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m120\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ prepare_attention_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mPrepareAttentionM…\u001b[0m │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m120\u001b[0m) │     \u001b[38;5;34m58,080\u001b[0m │ lambda_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ lambda_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
              "│                     │                   │            │ prepare_attentio… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m120\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m120\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ lambda_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
              "│                     │                   │            │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m120\u001b[0m) │        \u001b[38;5;34m240\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m240\u001b[0m) │     \u001b[38;5;34m29,040\u001b[0m │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m240\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m120\u001b[0m) │     \u001b[38;5;34m28,920\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m120\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_2 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m120\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│                     │                   │            │ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m120\u001b[0m) │     \u001b[38;5;34m58,080\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│                     │                   │            │ prepare_attentio… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m120\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_3 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m120\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│                     │                   │            │ dropout_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m120\u001b[0m) │        \u001b[38;5;34m240\u001b[0m │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m240\u001b[0m) │     \u001b[38;5;34m29,040\u001b[0m │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m240\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m120\u001b[0m) │     \u001b[38;5;34m28,920\u001b[0m │ dropout_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m120\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_4 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m120\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│                     │                   │            │ dropout_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m120\u001b[0m) │        \u001b[38;5;34m240\u001b[0m │ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lambda_5 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m120\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ prepare_pooling_ma… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mPreparePoolingMas…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ safe_masked_mean    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ lambda_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
              "│ (\u001b[38;5;33mLambda\u001b[0m)            │                   │            │ prepare_pooling_… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lambda_6 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ safe_masked_mean… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)        │      \u001b[38;5;34m7,260\u001b[0m │ lambda_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)        │        \u001b[38;5;34m120\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ go_terms_output     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10236\u001b[0m)     │    \u001b[38;5;34m624,396\u001b[0m │ dropout_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ coords (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>,   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dpseq (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dihedral_layer      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ coords[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DihedralLayer</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,120</span> │ dpseq[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dihedral_projection │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">840</span> │ dihedral_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lambda_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dihedral_project… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span> │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span> │ lambda_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ safe_clip_layer_1   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SafeClipLayer</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lambda_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lambda_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ safe_clip_layer_… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ safe_clip_layer     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SafeClipLayer</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
              "│                     │                   │            │ safe_clip_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ padding_mask        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lambda_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ prepare_attention_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PrepareAttentionM…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">58,080</span> │ lambda_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ lambda_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
              "│                     │                   │            │ prepare_attentio… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
              "│                     │                   │            │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">29,040</span> │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">28,920</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│                     │                   │            │ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">58,080</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│                     │                   │            │ prepare_attentio… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│                     │                   │            │ dropout_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span> │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">29,040</span> │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">28,920</span> │ dropout_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│                     │                   │            │ dropout_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span> │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lambda_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ prepare_pooling_ma… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PreparePoolingMas…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ safe_masked_mean    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │                   │            │ prepare_pooling_… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lambda_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ safe_masked_mean… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,260</span> │ lambda_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ go_terms_output     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10236</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">624,396</span> │ dropout_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,634,770\u001b[0m (10.05 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,634,770</span> (10.05 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m878,256\u001b[0m (3.35 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">878,256</span> (3.35 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,756,514\u001b[0m (6.70 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,756,514</span> (6.70 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuD8JkVL82Fu"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aON2RYIZe4t7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "outputId": "81dd4e19-dffb-4b18-f0aa-65d274a76a7d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@title Plot loss and accuracy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_training_history(history, metrics_to_plot=[\"loss\", \"binary_accuracy\"]):\n",
        "    \"\"\"\n",
        "    Plots training history for given metrics.\n",
        "\n",
        "    Args:\n",
        "        history: Keras History object returned by model.fit()\n",
        "        metrics_to_plot: List of metrics to plot. Common options: ['loss', 'binary_accuracy']\n",
        "    \"\"\"\n",
        "    if not history or not hasattr(history, \"history\"):\n",
        "        print(\"Invalid history object.\")\n",
        "        return\n",
        "\n",
        "    history_dict = history.history\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    for i, metric in enumerate(metrics_to_plot):\n",
        "        plt.subplot(1, len(metrics_to_plot), i + 1)\n",
        "        plt.plot(history_dict[metric], label=f\"Train {metric}\")\n",
        "        val_metric = f\"val_{metric}\"\n",
        "        if val_metric in history_dict:\n",
        "            plt.plot(history_dict[val_metric], label=f\"Val {metric}\")\n",
        "        plt.title(metric.replace('_', ' ').title())\n",
        "        plt.xlabel(\"Epochs\")\n",
        "        plt.ylabel(metric.replace('_', ' ').title())\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_training_history(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZRZpZwd2yF3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41bab038-6792-412e-f77e-ac7a29a1a158"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step\n",
            "Total proteins in JSON: 12632\n",
            "Proteins with latent representations: 1264\n",
            "Final dataset size: 1264\n",
            "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - binary_accuracy: 0.9944 - loss: 0.0317\n",
            "\n",
            "Test Results: Loss = 0.0324, Binary Accuracy = 0.9942\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Get labels\n",
        "X_test_seq, y_test = get_sequence_and_labels(json_data, test_ids, go_term_to_index=go_term_to_index)\n",
        "\n",
        "# Step 2: Get latent space from pretrained sequence model\n",
        "X_latent_test = latent_model.predict(X_test_seq, batch_size=64)\n",
        "\n",
        "# Step 3: Build a dictionary with latent vectors keyed by protein_id\n",
        "x_test_dict = {}\n",
        "for i, protein_id in enumerate(test_ids):  # ← use test_ids, not val_ids\n",
        "    x_test_dict[protein_id] = X_latent_test[i]\n",
        "\n",
        "# Step 4: Create the test dataset using your custom loader\n",
        "test_loader = JsonDataLoaderWithLatentSpace(\n",
        "    in_data=json_data,\n",
        "    batch_size=4,\n",
        "    go_term_vocabulary=go_term_vocabulary,\n",
        "    go_term_to_index=go_term_to_index,\n",
        "    latent_representations_dict=x_test_dict,\n",
        "    latent_dim=100,\n",
        "    coords_mask_plddt_th=70.0,\n",
        "    fixed_max_len=fixed_max_len # Pass fixed_max_len to data loader\n",
        ")\n",
        "\n",
        "# Step 5: Evaluate the model\n",
        "results = model.evaluate(test_loader)\n",
        "print(f\"\\nTest Results: Loss = {results[0]:.4f}, Binary Accuracy = {results[1]:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(test_loader)"
      ],
      "metadata": {
        "id": "OWuVjudLh4Ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d26370f-e825-434f-f8bd-c57317c6c5e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Convert probabilities to binary predictions\n",
        "y_pred_binary = (pred > 0.5).astype(int)\n",
        "\n",
        "# Calculate metrics\n",
        "precision = precision_score(y_test, y_pred_binary, average='micro')\n",
        "recall = recall_score(y_test, y_pred_binary, average='micro')\n",
        "f1 = f1_score(y_test, y_pred_binary, average='micro')\n",
        "\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")"
      ],
      "metadata": {
        "id": "CLr4fQmgh5S2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae1d5a5a-cc1f-4798-e04d-ea460f494aa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.6938\n",
            "Recall: 0.1193\n",
            "F1-score: 0.2036\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}